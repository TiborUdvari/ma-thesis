{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afc5179e-517e-4ba5-ad8e-8d28d6502fbb",
   "metadata": {},
   "source": [
    "# Processing Libraries ( Contributions ) Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14c23f0-053b-4bc0-8593-83797abdd388",
   "metadata": {},
   "source": [
    "The libraries are made available through [this endpoint](https://download.processing.org/contribs) on the Processing website. This only contains the latest versions of libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44263d5-766f-4cb0-a521-5242da4709ab",
   "metadata": {},
   "source": [
    "**It is not clear where to get all the other data, I need to ask in the forum**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a2dd1d1e-3238-4028-a80b-574fa366d81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import git\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b38a636-8f44-488c-b12c-bc3a7da83cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "library\n",
      "name=proscene\n",
      "authors=[Jean Pierre Charalambos](http://otrolado.info)\n",
      "url=http://otrolado.info\n",
      "categories=3D,Animation,Geometry,GUI,I/O,Utilities\n",
      "sentence=This project is deprecated and will soon no longer be available. Download the nub library instead.\n",
      "paragraph=Main features include: 1. Default interactivity through the mouse and keyboard that simply does what you expect; 2. Generic support for Human Interface Devices; 3. Arcball, walkthrough and third person camera modes; 4. Hierarchical coordinate systems (frames), with functions to convert between them; 5. Coordinate systems can easily be moved with the mouse. 6. Keyframes; 7. Object picking; 8. Keyboard shortcuts and camera profiles customization; 8. Animation framework; 9. Screen drawing; and, 10. Off-screen rendering mode support.\n",
      "version=33\n",
      "prettyVersion=3.0.1\n",
      "minRevision=256\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p libraries\n",
    "!wget -q -O libraries/current-libs.txt https://download.processing.org/contribs\n",
    "!head libraries/current-libs.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdcb556-1c0b-4d88-a4d6-9fccaa6441f1",
   "metadata": {},
   "source": [
    "To reconstruct the history, I will need snapshots of the `contributions` file after each change. However, capturing individual updates to libraries will be challenging, since once they are validated, the library authors control update streams. This is achieved by having a trusted endpoint that returns the latest version and build of the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0966b71d-ed71-4cd5-9202-35d432ae456c",
   "metadata": {},
   "outputs": [],
   "source": [
    "website_repo = 'https://github.com/processing/processing-web-archive.git'\n",
    "folder = 'libraries'\n",
    "local_dir = 'libraries/processing-web-archive'\n",
    "\n",
    "contrib_fn = \"contrib_generate/contributions.txt\"\n",
    "\n",
    "if not os.path.exists(local_dir):\n",
    "    repo = git.Repo.clone_from(website_repo, local_dir)\n",
    "else:\n",
    "    print(f\"Repository already exists at {local_dir}, skipping clone.\")\n",
    "\n",
    "g = git.Git(local_dir)\n",
    "\n",
    "# Get log history\n",
    "loginfo = g.log('--pretty=%H %ct', '--', contrib_fn)\n",
    "\n",
    "# Loop through logs and checkout each version\n",
    "for line in loginfo.splitlines():\n",
    "    line = line.strip()\n",
    "\n",
    "    commit_hash, timestamp = line.split(\" \")\n",
    "    print(commit_hash)\n",
    "    g.checkout(f'{commit_hash}') #This could be spead up, but maybe not worth it\n",
    "    dest_fn = f'{folder}/contributions-{timestamp}-{commit_hash}.txt'\n",
    "\n",
    "    # Copy the file to the destination\n",
    "    shutil.copy(f'{local_dir}/{contrib_fn}', dest_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ec1efa-3331-4b65-9ac1-852263f5f447",
   "metadata": {},
   "source": [
    "## Identifying events accross the libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f3be91-84e5-43f1-8151-5e4797b8b233",
   "metadata": {},
   "source": [
    "### Aggregating all the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3dbf13d3-8b5e-4996-85a0-58aad6efa0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs = []\n",
    "\n",
    "def read_and_parse_file(file_path, timestamp):\n",
    "    with open(file_path, 'r') as f:\n",
    "        text = f.read()\n",
    "\n",
    "    # Function to parse a single block (could be library, tool, or mode)\n",
    "    def parse_block(block, block_type):\n",
    "        block_dict = {}\n",
    "        lines = block.strip().split(\"\\n\")[1:]  # Exclude the first line containing block type\n",
    "        for line in lines:\n",
    "            key, value = line.split(\"=\", 1)\n",
    "            block_dict[key] = value\n",
    "        block_dict['timestamp'] = timestamp\n",
    "        block_dict['type'] = block_type\n",
    "        return block_dict\n",
    "\n",
    "    all_parsed = []\n",
    "    \n",
    "    # Split by blank lines and iterate through each block\n",
    "    for block in text.strip().split(\"\\n\\n\"):\n",
    "        first_line = block.split(\"\\n\")[0]\n",
    "        if first_line in ['library', 'tool', 'mode']:\n",
    "            all_parsed.append(parse_block(block, first_line))\n",
    "\n",
    "    return pd.DataFrame(all_parsed)\n",
    "\n",
    "for file_path in glob.glob(f'{folder}/contributions-*.txt'):\n",
    "    timestamp = os.path.basename(file_path).split('.')[0].split('-')[1]\n",
    "    df = read_and_parse_file(file_path, timestamp)\n",
    "    all_dfs.append(df)\n",
    "\n",
    "combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "combined_df.to_csv(\"temp.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffa22f2-4e05-4725-85b2-93bd30d64282",
   "metadata": {},
   "source": [
    "## Preserve only changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "65abc287-4b9f-449a-85d6-bc1f7c7c5f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the DataFrame by 'id' and 'timestamp'\n",
    "sorted_df = combined_df.sort_values(by=['id', 'timestamp'])\n",
    "\n",
    "# Compute the 'changed' column based on the 'version' column\n",
    "sorted_df['changed'] = sorted_df.groupby('id')['version'].apply(lambda x: x != x.shift(1)).reset_index(level=0, drop=True)\n",
    "\n",
    "# Add a removed at column to signify when it wasn't in the database anymore\n",
    "# Sort the DataFrame by 'id' and 'timestamp'\n",
    "sorted_df = sorted_df.sort_values(by=['id', 'timestamp'])\n",
    "\n",
    "# Group by 'id' and then collect lists of timestamps for each 'id'\n",
    "grouped = sorted_df.groupby('id')['timestamp'].apply(list).reset_index()\n",
    "\n",
    "# Initialize a list to store information about removed libraries\n",
    "removed_libraries = []\n",
    "\n",
    "# Iterate through each group to check for removals\n",
    "for idx, row in grouped.iterrows():\n",
    "    id_ = row['id']\n",
    "    timestamps = row['timestamp']\n",
    "\n",
    "    # Check if this library exists in the latest timestamp\n",
    "    if timestamps[-1] != sorted_df['timestamp'].max():\n",
    "        removed_libraries.append({'id': id_, 'removed_at': timestamps[-1]})\n",
    "\n",
    "# Create a DataFrame for removed libraries\n",
    "df_removed = pd.DataFrame(removed_libraries)\n",
    "\n",
    "sorted_df = pd.merge(sorted_df, df_removed, on='id', how='left')\n",
    "\n",
    "# Filter only the rows where 'changed' is True\n",
    "filtered_df = sorted_df[sorted_df['changed'] == True]\n",
    "\n",
    "# Drop the 'changed' column\n",
    "final_df = filtered_df.drop('changed', axis=1)\n",
    "\n",
    "# Optionally, reset the index\n",
    "final_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Now, df_removed contains the 'id' and the last known timestamp ('removed_at') for removed libraries\n",
    "final_df.to_csv(\"libraries-data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
