{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2285f0fa-49cc-4bce-864f-35528584d0b3",
   "metadata": {},
   "source": [
    "# Processing Releases Dataset\n",
    "The releases are compiled from multiple files. It was updated under the file `revisions.txt` but it was purged from time to time so I have to reconstruct it using versions I found with `git blame`.\n",
    "\n",
    "Later revisions are obtained directly from Github, which includes extra useful information such as downloads.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76ee5899-c892-4c26-b83b-752968aa482b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chardet\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: chardet\n",
      "Successfully installed chardet-5.2.0\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests) (2023.5.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install chardet\n",
    "!pip install requests\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import chardet\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3632004-3156-4638-b1be-787f894ef8dc",
   "metadata": {},
   "source": [
    "# Revisions.txt data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e91f468-f2af-461b-989b-eac8c159629f",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"releases\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "76ac3376-b1f1-4c7e-b7be-34ad1b1da938",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2023-09-25 10:24:15--  https://raw.githubusercontent.com/processing/processing/5f289537698f504499bfda0084b4c5f3f1ac0912/build/shared/revisions.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 82164 (80K) [text/plain]\n",
      "Saving to: ‘releases/1.txt’\n",
      "\n",
      "     0K .......... .......... .......... .......... .......... 62% 2.28M 0s\n",
      "    50K .......... .......... ..........                      100% 9.34M=0.02s\n",
      "\n",
      "2023-09-25 10:24:15 (3.19 MB/s) - ‘releases/1.txt’ saved [82164/82164]\n",
      "\n",
      "--2023-09-25 10:24:15--  https://raw.githubusercontent.com/processing/processing/16dd0e77e70810c87d9f7b4a195ef72fe6e048f6/build/shared/revisions.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 208938 (204K) [text/plain]\n",
      "Saving to: ‘releases/2.txt’\n",
      "\n",
      "     0K .......... .......... .......... .......... .......... 24% 2.27M 0s\n",
      "    50K .......... .......... .......... .......... .......... 49% 6.51M 0s\n",
      "   100K .......... .......... .......... .......... .......... 73% 3.56M 0s\n",
      "   150K .......... .......... .......... .......... .......... 98% 13.2M 0s\n",
      "   200K ....                                                  100% 7.53T=0.05s\n",
      "\n",
      "2023-09-25 10:24:16 (4.29 MB/s) - ‘releases/2.txt’ saved [208938/208938]\n",
      "\n",
      "--2023-09-25 10:24:16--  https://raw.githubusercontent.com/processing/processing/master/build/shared/revisions.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 367613 (359K) [text/plain]\n",
      "Saving to: ‘releases/3.txt’\n",
      "\n",
      "     0K .......... .......... .......... .......... .......... 13% 2.21M 0s\n",
      "    50K .......... .......... .......... .......... .......... 27% 6.82M 0s\n",
      "   100K .......... .......... .......... .......... .......... 41% 3.62M 0s\n",
      "   150K .......... .......... .......... .......... .......... 55% 11.7M 0s\n",
      "   200K .......... .......... .......... .......... .......... 69% 12.7M 0s\n",
      "   250K .......... .......... .......... .......... .......... 83% 4.40M 0s\n",
      "   300K .......... .......... .......... .......... .......... 97% 22.8M 0s\n",
      "   350K ........                                              100% 42.4M=0.06s\n",
      "\n",
      "2023-09-25 10:24:16 (5.46 MB/s) - ‘releases/3.txt’ saved [367613/367613]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download and concatenate data files\n",
    "def read_file_with_unknown_encoding(filepath):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        content = f.read()\n",
    "        \n",
    "    encodings_to_try = ['utf-8', 'latin1', 'ascii', 'cp1252']  # Add more encodings to try if you wish\n",
    "    for encoding in encodings_to_try:\n",
    "        try:\n",
    "            return content.decode(encoding)\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "            \n",
    "    return None  # or raise an exception if you wish\n",
    "\n",
    "# Define folder and URLs\n",
    "releases_1 = \"https://raw.githubusercontent.com/processing/processing/5f289537698f504499bfda0084b4c5f3f1ac0912/build/shared/revisions.txt\"\n",
    "releases_2 = \"https://raw.githubusercontent.com/processing/processing/16dd0e77e70810c87d9f7b4a195ef72fe6e048f6/build/shared/revisions.txt\"\n",
    "releases_3 = \"https://raw.githubusercontent.com/processing/processing/master/build/shared/revisions.txt\"\n",
    "\n",
    "# Create folder and download files\n",
    "os.system(f'mkdir -p {folder}')\n",
    "os.system(f'wget {releases_1} -O {folder}/1.txt')\n",
    "os.system(f'wget {releases_2} -O {folder}/2.txt')\n",
    "os.system(f'wget {releases_3} -O {folder}/3.txt')\n",
    "\n",
    "# Read files with unknown encoding\n",
    "file_contents = []\n",
    "for i in range(1, 4):  # For files 1.txt, 2.txt, and 3.txt\n",
    "    filepath = os.path.join(folder, f\"{i}.txt\")\n",
    "    content = read_file_with_unknown_encoding(filepath)\n",
    "    if content:\n",
    "        file_contents.append(content)\n",
    "\n",
    "# Combine and write to a new file\n",
    "combined_content = ''.join(file_contents)\n",
    "with open(os.path.join(folder, 'combined.txt'), 'w', encoding='utf-8') as f:\n",
    "    f.write(combined_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05c2f2a8-9218-4ea7-a141-4cb85a7c6ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(folder + os.sep + \"combined.txt\", \"r\") as f:\n",
    "    file_content = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f23bbe65-7343-43c7-a2fc-5ad70dbddc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"(?P<entry>(?:ABOUT )?(?:PROCESSING )?(?P<version>\\d.\\w+(?:.\\w+)*)?(?: \\()*REV (?P<rev>\\d{3,4})\\)?(?: \\S+? -)?(?: - )?(?P<date>\\d+ \\w+ \\d+)?(?:[ \\S]*))\\n\\n(?P<content>.+?)(?=^PROCESSING|^ABOUT|(?:. ){15,})\"\n",
    "\n",
    "data_list = []\n",
    "\n",
    "for match in re.finditer(pattern, file_content, re.DOTALL | re.MULTILINE):\n",
    "    data_dict = {\n",
    "        'entry': match.group('entry'),\n",
    "        'version': match.group('version') if match.group('version') else None,\n",
    "        'revision': int(match.group('rev')) if match.group('rev') else None,\n",
    "        'published_at': match.group('date') if match.group('date') else None,\n",
    "        'body': match.group('content') if match.group('content') else None\n",
    "    }\n",
    "    \n",
    "    data_list.append(data_dict)\n",
    "\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "def parse_date(date_str):\n",
    "    if pd.isna(date_str) or not date_str:\n",
    "        return pd.NaT\n",
    "    try:\n",
    "        return pd.to_datetime(date_str, errors='coerce', format='%d %B %Y')\n",
    "    except Exception:\n",
    "        return date_str  # return the original string if parsing fails\n",
    "\n",
    "df['published_at'] = df['published_at'].apply(parse_date)\n",
    "df['published_at'] = pd.to_datetime(df['published_at'], errors='coerce')\n",
    "df['published_at'] = df['published_at'].dt.tz_localize('America/New_York')\n",
    "df = df.drop_duplicates(subset=['revision'])\n",
    "\n",
    "# versions 21 through 23 dealt with getting the beast to work smoothly for the numer workshop\n",
    "# PROCESSING REV 0172 through 0175 are grouped together\n",
    "\n",
    "df.sort_values(by='revision', ascending=True, inplace=True)\n",
    "revisionstxt_df_final = df\n",
    "#df.to_csv('temp2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fb8479-54ae-42ce-a04e-491a293c5ca1",
   "metadata": {},
   "source": [
    "# Github Releases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dbdff1b9-bd23-4a21-a687-9714c93a99c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert the list of asset dictionaries to a flat dictionary\n",
    "def flatten_assets(assets_list):\n",
    "    flattened = {}\n",
    "    for i, asset in enumerate(assets_list):\n",
    "        for key, value in asset.items():\n",
    "            flattened[f'asset_{i+1}_{key}'] = value\n",
    "    return flattened\n",
    "\n",
    "def get_all_releases(owner, repo):\n",
    "    url = f\"https://api.github.com/repos/{owner}/{repo}/releases\"\n",
    "    page = 1\n",
    "    all_releases = []\n",
    "\n",
    "    while True:\n",
    "        params = {'page': page}\n",
    "        response = requests.get(url, params=params)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to get data: {response.content}\")\n",
    "            break\n",
    "\n",
    "        releases = json.loads(response.text)\n",
    "        if not releases:  # Exit the loop if no more releases\n",
    "            break\n",
    "\n",
    "        all_releases.extend(releases)\n",
    "        page += 1  # Increment the page number for the next iteration\n",
    "\n",
    "    return all_releases\n",
    "\n",
    "all_releases = get_all_releases(\"processing\", \"processing\") +  get_all_releases(\"processing\", \"processing4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c3831cba-c283-466e-bb99-517717ead123",
   "metadata": {},
   "outputs": [],
   "source": [
    "github_df = pd.DataFrame(pd.json_normalize(all_releases))\n",
    "\n",
    "# Apply the function to the 'assets' column\n",
    "flattened_assets_df = github_df['assets'].apply(flatten_assets).apply(pd.Series)\n",
    "\n",
    "# Concatenate the original DataFrame with the new DataFrame\n",
    "github_df_final = pd.concat([github_df, flattened_assets_df], axis=1)\n",
    "github_df_final = github_df_final.sort_values(by='published_at', ascending=True)\n",
    "github_df_final['published_at'] = pd.to_datetime(github_df_final['published_at'], errors='coerce')\n",
    "\n",
    "pattern = r'processing-(?:0*(\\d+)-)?([\\w.]+)'\n",
    "\n",
    "github_df_final[['revision', 'version']] = github_df_final['tag_name'].str.extract(pattern)\n",
    "github_df_final['revision'] = github_df_final['revision'].astype('Int64')\n",
    "\n",
    "github_df_final.to_csv('temp-github.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8683cad7-65dc-4a54-8ebb-b46cdf8e536b",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df_vertical = pd.concat([revisionstxt_df_final, github_df_final], axis=0)\n",
    "concat_df_vertical['revision'] = concat_df_vertical['revision'].astype('Int64') #This supports NaN\n",
    "concat_df_vertical = concat_df_vertical.dropna(subset=['revision'])\n",
    "\n",
    "concat_df_vertical = concat_df_vertical.sort_values(by=['revision', 'published_at'], ascending=[True, True])\n",
    "\n",
    "concat_df_vertical = concat_df_vertical.drop_duplicates(subset=['revision'])\n",
    "concat_df_vertical.to_csv('releases-data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6dffdd17-1c0b-402d-ac6f-6937f7d0cd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(folder + os.sep + \"1.txt\", \"r\") as f:\n",
    "    content = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "50a17444-39c0-4fd1-bbcf-f27f2e1eb258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release_Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69</td>\n",
       "      <td>2004-03-28</td>\n",
       "      <td>this is yet another bug fix release, which rep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68</td>\n",
       "      <td>2004-02-02</td>\n",
       "      <td>this is a bug fix release, not the planned ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>2003-10-28</td>\n",
       "      <td>another bug fix release. high importance for p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66</td>\n",
       "      <td>2003-10-19</td>\n",
       "      <td>several important bug fixes in this release, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65</td>\n",
       "      <td>2003-09-30</td>\n",
       "      <td>one major bug fix that repairs nastiness in dr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Release_Number       Date  \\\n",
       "0              69 2004-03-28   \n",
       "1              68 2004-02-02   \n",
       "2              67 2003-10-28   \n",
       "3              66 2003-10-19   \n",
       "4              65 2003-09-30   \n",
       "\n",
       "                                             Content  \n",
       "0  this is yet another bug fix release, which rep...  \n",
       "1  this is a bug fix release, not the planned ver...  \n",
       "2  another bug fix release. high importance for p...  \n",
       "3  several important bug fixes in this release, s...  \n",
       "4  one major bug fix that repairs nastiness in dr...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = r\"ABOUT REV (\\d+)(?: - (\\d+ \\w+ \\d+)(?: \\w+)?)?\\n\\n(.+?)(?=\\n\\nABOUT REV|\\Z)\"\n",
    "matches = re.findall(pattern, content, re.DOTALL)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(matches, columns=[\"Release_Number\", \"Date\", \"Content\"])\n",
    "\n",
    "# Custom date parsing function\n",
    "def parse_date(date_str):\n",
    "    if pd.isna(date_str):\n",
    "        return pd.NaT\n",
    "    try:\n",
    "        return pd.to_datetime(date_str, errors='raise', format='%d %B %Y')\n",
    "    except Exception:\n",
    "        return date_str  # return the original string if parsing fails\n",
    "\n",
    "# Apply custom date parsing\n",
    "df['Date'] = df['Date'].apply(parse_date)\n",
    "df['Release_Number'] = df['Release_Number'].astype(int)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "abd0f546-44e3-43ba-a9ff-3561ec5f8727",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(folder + os.sep + \"2.txt\", \"r\") as f:\n",
    "    content2 = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ce1d2f27-1ff3-40ca-8d1a-f5107840c946",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"ABOUT REV (\\d+)(?: - (\\d+ \\w+ \\d+)(?: \\w+)?)?\\n\\n(.+?)(?=\\n\\nABOUT REV|\\Z)\"\n",
    "matches = re.findall(pattern, content2, re.DOTALL)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(matches, columns=[\"Release_Number\", \"Date\", \"Content\"])\n",
    "\n",
    "# Custom date parsing function\n",
    "def parse_date(date_str):\n",
    "    if pd.isna(date_str):\n",
    "        return pd.NaT\n",
    "    try:\n",
    "        return pd.to_datetime(date_str, errors='raise', format='%d %B %Y')\n",
    "    except Exception:\n",
    "        return date_str  # return the original string if parsing fails\n",
    "\n",
    "# Apply custom date parsing\n",
    "df['Date'] = df['Date'].apply(parse_date)\n",
    "df['Release_Number'] = df['Release_Number'].astype(int)\n",
    "\n",
    "df.to_csv('dataframe_output.csv', index=False)\n",
    "# last one 161"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdafe07d-a8a5-400d-a22d-7bbc2540cec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Missing the following\n",
    "# ABOUT REV 0070 - MEGABUCKET - 29 September 2004\n",
    "# ABOUT REV 0071 \n",
    "# ABOUT REV 0137 - 30 May 2008 \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
