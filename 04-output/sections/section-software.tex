% Software
\specialsection{Software}{}{black}{white}

\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{images/cathedral-or-bazaar.jpeg}
	\caption{2019 p5js contributor conference}
	\label{fig:p5ps-conference}
\end{figure}

\todo[inline]{Include image credit p5js project lead from zotero}

\subsection{Software Development Models}

The Processing project is commonly perceived as mainly the Integrated Development Environment (IDE) and its core components, which are crucial for basic operations. However, external libraries augmenting the system’s capabilities are also essential to the ecosystem.

This chapter delves into the distinctive mix of software development as applied to these two foundational aspects, from the core project, relying on a few dedicated contributors to the decentralized bazaar of library contributions and their interplay. Afterward, the mixed motivations of these different groups of code contributors are analyzed through a lens of technological, social, and economic factors.

Eric S. Raymond’s "The Cathedral and the Bazaar" \parencite{raymondCathedralBazaar1999} identifies two open-source software development methodologies relevant to the processing project. 

The Cathedral model, exemplified by early GNU projects under Richard Stallman, is characterized by meticulous planning and centralized control \parencite{stallmanFreeSoftwareFree2002}. This model functions much like the construction of a cathedral, where a small group of experts crafts a complex, well‐organized structure over a long period, similar to the tiny number of contributors to the core processing project. 

In contrast, the Bazaar model, which gained prominence with the 
development of the Linux Kernel espouses a more decentralized approach. Spearheaded by Linus Torvalds, this model resembles a bazaar, where contributors from diverse backgrounds bring in their unique contributions, leading to rapid iterations and an evolving software landscape reflective of the library’s ecosystem. 
These two models represent endpoints on a continuum, with many real-world projects, including Processing, displaying characteristics of both. 

While the Cathedral and Bazaar models provide a structural understanding of software development practices, exploring why individuals engage in these projects is equally essential. The sustainability of open-source projects like Processing hinges on the continuous flow of software contributions. Without the active and sustained involvement of contributors, the long-term viability of such projects is at risk. To gain a deeper understanding of what drives these contributions, we turn to the established taxonomy by Bonaccorsi et al. as seen in Table~\ref{tab:taxonomy} \parencite{bonaccorsiComparingMotivationsIndividual2006} to facilitate comparison with other open-source projects.

This framework categorizes the motivations behind open‐source
contributions into economic, social, and technological domains.

The following sections analyze the dynamics and motivations of contributions to the core and libraries, respectively. The analysis combines quantitative data from software releases and version control systems with insights from interviews with key code contributors.

\begin{table}
    \begin{tabularx}{\textwidth}{l l} 
    \toprule
    Motivation area & Micro level \\
    \midrule
    Economic & Monetary rewards \\
     & Low opportunity costs \\
     & Gaining a reputation among peers \\
     & Gaining future career benefits \\
    \midrule
    Social & Fun to program (Loving to code) \\
     & Altruism (gift economy) \\
     & Sense of belonging to the community \\
     & Fight against proprietary software \\
    \midrule
    Technological & Learning \\
     & Contributions and feedback from the community \\
     & Working with a bleeding-edge technology \\
     & Scratching a personal itch \\
    \bottomrule
    \end{tabularx} 
    \caption[Motivations taxonomy]{Taxonomy of individual programmers’ Motivations. Adapted from \parencite{bonaccorsiComparingMotivationsIndividual2006}}
    \label{tab:taxonomy}

\end{table}

\subsection{Core Contributions}
The development environment plays a vital role in the processing project, setting the foundation for all functionalities. Contributions to the main code of the project are essential to the ecosystem, and without them, the other elements cannot function properly. It is essential to understand the motivations of the people who built and contributed to the project to analyze it effectively.

The analysis draws on public release logs and version control histories but with limitations. Key early project details are missing, as initial documentation practices were suboptimal. Multiple version control system changes likely caused data inconsistencies. While the Processing project’s GitHub logs offer extensive data, they only partially capture the earliest contributions. The complexity of the early 2000s software release, exemplified by the mini CD distribution in October 2002 (Figure~\ref{fig:processing-cd}), contrasts with today’s streamlined Git updates.

Fry indicated that early version control system limitations led him to manually commit code from other contributors, ensuring recognition in the logs despite lacking direct attribution in the repository’s interface. This practice initially over-represented Fry’s contributions, owing to challenges in proper crediting using CVS and later Subversion. \enquote{While things were in CVS, I had to do the commits myself, but always noted where things came from in the commit history}, Fry stated, noting a slight improvement with Subversion and Google Code. He emphasized, \enquote{GitHub was the first meaningful change where it really helped with the collaborative side of development}.

Following this, interviews were conducted with key figures: Ben Fry, the lead software engineer; Karsten Schmidt, a contributing coder; and Simon Greenwold, a core contributor and member of MIT’s Aesthetics and Computation Group during the project’s inception. These individuals were chosen based on their contributions, as evidenced in the Alpha Forum’s active period (Figure~\ref{fig:alpha-commits}).

Ben Fry’s role as the leading technical engineer was significant in developing the Processing project. The observations of his collaborators underscore this. Casey Reas emphasizes Fry’s primary role: ’I think one thing that’s important to clarify is that Ben Fry, my collaborator, is the primary software engineer of the project’ \parencite[p. 330]{conradGraphicDesignPostdigital2021}. Simon Greenwold further corroborates this, highlighting Fry’s authoritative approach: \enquote{He’s maintaining strong control, like it’s his code base. I think that’s part of why it’s great}.

\begin{figure}
	% \centering
	\includegraphics[width=0.7\textwidth]{images/processing-mini-cd.png}
	\caption[Mini CD]{Processing Mini CD, October 2002}
	\label{fig:processing-cd}
\end{figure}

\input{foldouts/version-control.tex}

% Initial Release: August 9 2001 -> Alpha Forum initial post: August 2 2002

Completing the development of Bagel, the initial render engine, Ben Fry had established a robust initial code base a year before the debut of the Processing Alpha forum involving other contributors. As Fry recounts, this foundational phase was critical but had challenges. He faced significant hurdles with MIT’s Technology Licensing Office (TLO), specifically regarding intellectual property rights and the public release of the code. These challenges, stemming from MIT and the Media Lab’s evolving stance on open-source software, resulted in prolonged delays and a waiting period for necessary clearances. These early struggles with IP rights and public code release paved the way for Processing’s distinctive approach to Creativity Sustaining Tools (CST) for visual arts \parencite{shneidermanCreativitySupportTools2002}.

Simon Greenwold underscores this transition, noting Processing’s early adoption of an open-source model, a notable deviation in its field. He states, \enquote{Processing was notable in being open source early, ... probably unique in its class}, thereby highlighting its pioneering role. In contrast, contemporaneous toolkits like Director or Flash were predominantly closed-source.

Processing’s development initially adhered to a centralized, cathedral-style model characterized by structured, top-down control. The introduction of the alpha forum, however, marked a significant shift towards a decentralized, bazaar-style approach, encouraging community participation and collaborative code sharing.

This transition in Processing’s development mirrors the early stages of other open-source projects like Linux, which also started with a solid foundation built by a single developer and evolved through community contributions. This shift to a more inclusive and collaborative model is a common trend in developing open-source software.

The impact of this shift was evident in specific revision logs. For instance, the release notes from 27/05/2003 - rev 55 marked a turning point with the incorporation of code from external contributors, reflecting a move towards a community-driven development model. As Fry points out in these notes, \enquote{This is the first release to include explicit support for audio, video, and network. Perhaps more exciting is that this code was developed by developers other than me}. Following this, rev 56 further started to showcase a diversity of community involvement, not limited to code contributions; members engaged in various activities, including testing, providing feedback, and enhancing documentation. This broadened participation exemplified the multifaceted nature of the bazaar model, where contributions extend beyond programming to encompass various aspects of software development.

Building on this community-centric approach, the project adhered to Eric S. Raymond’s principle: ’Treating your users as co-developers is your least-hassle route to rapid code improvement and effective debugging’ \parencite[27]{raymondCathedralBazaar1999}. This ethos was crucial in Processing’s evolution, particularly in the role of Ben Fry, who was integral in reviewing and integrating these diverse contributions, a strategy vital for the project’s sustained success and functionality \parencite{fryProcessingContributionGuide2022}.

As the community’s aspirations grew, a library system was introduced to accommodate the diverse needs of the project, a topic explored in greater depth in the following section.

Eric S. Raymond’s ’Release early, release often’ philosophy further propelled Processing’s vibrant development \parencite[28]{raymondCathedralBazaar1999}. This approach, which greatly benefited Linux, enabled the rapid incorporation of contributions and fostered a responsive environment. The early phase of Processing, with 162 revisions prior to version 1 as shown in Figure~\ref{fig:releases-lines} and Table~\ref{tab:release-statistics}, was characterized by frequent updates, echoing Raymond’s observation about Linux’s development: ’In those early times (around 1991) it was not unknown for Linus Torvalds to release a new kernel more than once a day!’ \parencite[28]{raymondCathedralBazaar1999}.

However, Processing’s development was occasionally constrained by its nature as a side project. A comment from a revision in January 2003 highlights this: ’hopefully January 2003 will be a good month for p5, as I have a short bit of time to work on it [...] I hope to get a few revisions out this month so I can get back to my ’real’ work.’ This comment reveals Processing’s status as a secondary commitment for its core contributors.

This aspect of Processing’s development is detailed in a book titled Graphic Design in the Post-Digital Age, which notes that Processing began as a personal initiative, mainly developed during nights and weekends. The project’s funding sources, including MIT’s indirect support through Fry’s graduate stipend and the Interaction Design Institute Ivrea (IDII) ’s support through Reas’s salary, further underscore its ancillary status \parencite[396]{conradGraphicDesignPostdigital2021}.

This part-time commitment likely impacted the level of engagement in the project. As Raymond puts it, regarding Linux: \enquote{Linus was keeping his hacker/users constantly stimulated and rewarded—stimulated by the prospect of having an ego-satisfying piece of the action, rewarded by the sight of constant (even daily) improvement in their work} \parencite[28]{raymondCathedralBazaar1999}. In contrast, Processing’s intermittent development schedule may have limited its potential for maximal engagement.

This engagement disparity becomes more evident when examining the contribution landscape within the Processing project, as depicted in Figure~\ref{fig:alpha-commits}. The figure highlights Ben Fry’s central role, especially during the alpha forum phase. According to the available data, only six individuals, including Fry, appear to have actively contributed code to the repository, starkly contrasting the more than 1000 individuals engaged in forum discussions. Such a scenario suggests that Fry’s involvement was central and potentially overshadowing, limiting the scope for broader community contributions. 

As observed in many open-source initiatives, Fry’s predominant role in Processing raises critical concerns about the project’s resilience and sustainability. As corroborated by the subsequent visualizations ~\ref{fig:top12-github} his contributions were essential to keep the project running all this time. Over the past two decades, his extensive contributions have been indispensable. However, they also introduce a high-risk factor known as the \enquote{bus factor} \parencite{BusFactor2023}, reflecting the project’s vulnerability due to its heavy reliance on a few key individuals. This phenomenon, while common across open-source projects and often humorously depicted in popular culture \parencite{munroeDependency2020}, poses a significant challenge to the long-term health of Processing.

\input{foldouts/frequency-of-releases.tex}

Transitioning from the observed discrepancy between the comprehensive forum engagement and the limited core code contributors, it is pivotal to contextualize the commitment of these few key individuals within a structured framework. The taxonomy by Bonaccorsi et al.~\cite{bonaccorsiComparingMotivationsIndividual2006} provides a valuable lens through which to examine their motivations. This taxonomy categorizes the motivations into Economic, Social, and Technological factors, each offering a distinct perspective on the individual’s involvement.

Ben Fry’s technological motivation for developing Processing is deeply rooted in his personal experience with the cumbersome nature of existing tools for computational design. He aimed to create a platform that could sidestep these complexities, thus \enquote{scratching his own itch} and aid in teaching: \enquote{As researchers, all those extra steps just got in the way: we already knew how to do those things, and it just made the process tedious. So with Processing, we wanted to get closer to just having things show up and work}. 

This technological motivation is also echoed by Karsten Schmidt, whose initial involvement was propelled by the technological potential and the opportunities within the young Processing project: \enquote{The project was still young, there was a lot of stuff to do ... So I was not really a Processing user in the beginning. I became a user as I was contributing code to the actual tool}.

The economic incentives for engaging with Processing were not clear; Simon Greenwold’s statement highlights the absence of monetary gain and the low economic competition in the field: \enquote{There is no money in it. So who is going to come challenge it, right?}.

Nevertheless, despite the lack of financial motivation, Processing found significant traction in educational settings, where the alternatives left much to be desired. Greenwold’s assessment of the other tools available at the time underlines this point: \enquote{They were terrible. Just terrible. Yeah, Flash the director and Flash weren’t the same yet. They came together and then both died}.

The role of Processing in education is further substantiated by visual evidence, as illustrated in the community survey results conducted in 2016, which underscore its widespread adoption as a teaching tool (Figure~\ref{fig:community_survey}).

The social aspect of Fry’s motivations cannot be understated. His commitment to teaching and sharing knowledge, particularly with individuals who may not have coding expertise, signifies a strong social incentive that aligns with the open-source ethos of knowledge dissemination: \enquote{One of the most important things about the community for me personally is the motivation that comes from seeing really talented people use tools like this. That’s realy exciting and makes me want to work harder}, furthermore he states: \enquote{I learned to code at a very young age because other people shared their code... Their willingness to share, or even answer questions of a 9- or 10- or 12-year-old was a pretty incredible gift, and had a huge impact}.

Fry’s dedication to education and community engagement is a testament to the social motivations central to the Processing project. This commitment has fostered a supportive community and helped proliferate computational design skills among a broader audience, further amplifying the project’s impact.

In sum, the core contributors to Processing, who already possess strong technical skills, have been driven by a confluence of motivations. Technologically, they aimed to create a tool that would overcome the limitations of existing software. Economically, while there was no direct financial incentive, the educational adoption of Processing has increased its use and, indirectly, its importance in the computational design landscape. Socially, the emphasis on teaching and sharing knowledge has been a cornerstone of the project’s philosophy, ensuring that Processing remains an accessible and community-focused platform.

\begin{figure}[h!]
	\centering
	\includegraphics[width=\textwidth]{images/community-survey.png}
	\caption[Processing 2016 community survey]{Processing 2016 community survey result \parencite{processingfoundation2016CommunitySurvey2016}}
	\label{fig:community_survey}
\end{figure}

\subsection{The Ecosytem of Libraries}
The integration of libraries marked a significant turning point in the Processing ecosystem. These additions expanded the core platform’s capabilities, thus drawing a more comprehensive array of users and contributors. In the Processing community, libraries have been indispensable, acting as fundamental components that enhance the platform’s functionality and encourage inventive exploration.

This evolution in development philosophy is captured through the insights of Casey Reas, a co-founder of Processing. Reflecting on the initial phases of Processing’s development, Reas observed, \enquote{One of the important early decisions was to make what we call libraries. Ben [Fry] and I realized that we were in a bottleneck and getting in the way of how people wanted to expand and extend Processing} \parencite[329]{conradGraphicDesignPostdigital2021}. This statement underscores the pivotal shift towards an approach that embraced openness and collaborative progress in the development process.

The development and integration of libraries within the Processing ecosystem primarily exemplify the bazaar software development model, with a nod to the modularity characteristic of the GNU model. This is particularly evident in how some libraries evolved into core components of Processing.

A notable example is the development of the OpenGL renderer by Andrés Colubri. Initially developed independently to enhance Processing’s performance, this library was later integrated into the main software following its widespread acceptance within the community. This integration process is a classic example of the bazaar model, where development is open, collaborative, and evolutionary, driven by the diverse needs and contributions of the user base.  \parencite{fryProcessingContributionGuide2022}

While the modularity and individual contributions in this process resemble the GNU model, it is necessary to note that Processing’s approach reflects the dynamic and decentralized nature of the bazaar model more. The bazaar model emphasizes open collaboration and iterative development, aligning more with the community-driven development culture in Processing.

% Data analysis
Utilizing publicly available data from the Processing website archive, active libraries’ release history was successfully reconstructed between October 2011 and June 2014. This period reflects active development and frequent releases across multiple library categories, as Figure~\ref*{figure:libraries} illustrates. As a result of the absence of earlier data, it led to a somewhat arbitrary choice of interview subjects from this period. Consequently, the insights obtained may not fully represent the experiences within the Processing community at its beginning. Despite these limitations, the interviews provided valuable qualitative insights into the motivations and contributions of library developers. 

\input{foldouts/libraries.tex}

When analyzing interviews guided by Bonaccorsi et al.’s taxonomy, it becomes clear that technological innovation and community engagement were the primary driving forces behind the contributors. For instance, Karsten Schmidt’s experiences reflect a strong technological motivation. He aimed to push the limits of computational design’s expressive potential and, as a result, was compelled to create tools such as toxiclibs. This library aligned more closely with his vision than other frameworks, such as Flash or Director, which constrained creative expression within predefined roles and stage-based metaphors like directors, actors, and scripts. He said, \enquote{I really wanted something new, the way I can be more expressive with the actual computational side, the algorithm side}.

Similarly, Andreas Schlegel’s development of ControlP5 was driven by a practical need in his projects. He sought a tool that could provide a more intuitive and effective way of managing user interfaces within Processing. Schlegel’s creation of ControlP5 can be seen as ’scratching his own itch’, addressing personal challenges that benefit the wider community, as he noted: \enquote{ControlP5 started as a need for sliders and buttons to control the visuals I was working on}.

Marxer emphasized the collective effort and the shared sense of purpose among diverse individuals involved in open-source projects. He pointed out that these collaborative environments provide a platform for individuals from various backgrounds to learn from each other, contribute to a larger cause, and collectively advance the field. The social dynamics of open-source projects are crucial, as Marxer noted: \enquote{So it’s a sense of community. I think, in a sense, of working together as a society}.

According to Schlegel, his first library, oscP5, resulted from his final year project in his master’s in media arts and technology, which focused on designing a computer network for artistic applications. Initially, he did not intend to write it for the community, but that came as an afterthought. Similarly, Marxer reflected that Geomerative was initially a technological tool to \enquote{do letters that were joined by the serifs}, but it ended up being a whole project in generative typography.

As contributors like Schmidt and Schlegel delved deeper into the technology, they also became integral members of a burgeoning community. The collaborative ethos of the Processing community is evident in Marxer’s statement: \enquote{The goal is that all the work you do, nobody else should go through that and do it}. He was a DIY enthusiast, and he enjoyed seeing how things could be done. 

Schmidt also mentions that \enquote{open source was essentially amateur culture... there are labors of love for most people; it’s what’s done in their spare time or what comes out from some interesting work projects, what people want to share}. Although not the primary draw, economic factors emerge in the narrative, albeit as a secondary consideration. Schmidt’s indirect financial benefits from his open-source work underline this point: \enquote{in other times, I have indirectly made a living through my open-source work, but not directly from it}. Schlegel’s experience similarly reveals that while economic gain was not the goal, the recognition and opportunities that arose from his contributions had positive professional implications.

The interplay between these motivations underscores the complexity of open-source software development. The contributors are often initially attracted by the technological challenges. As they immerse themselves in the work, the community aspect becomes more significant, providing a supportive network for sharing and growth. This dynamic is particularly relevant when the necessary tools and infrastructure have not yet been built out at the beginning of a project.


